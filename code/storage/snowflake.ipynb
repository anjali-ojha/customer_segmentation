{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eef9b777efe0bf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T07:21:04.446533Z",
     "start_time": "2023-11-11T07:21:03.251641Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T07:21:04.479420Z",
     "start_time": "2023-11-11T07:21:04.449278Z"
    }
   },
   "outputs": [],
   "source": [
    "account_url = \"https://fx34478.us-central1.gcp.snowflakecomputing.com\"\n",
    "organization = \"ESODLJG\"\n",
    "account = \"RU55705\"\n",
    "user = \"DATA228PROJECT\"\n",
    "email = \"data228.project@gmail.com\"\n",
    "password = \"Project228\"\n",
    "database = 'project'\n",
    "schema = \"yelp_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da1e97e742e1b6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T07:21:10.678136Z",
     "start_time": "2023-11-11T07:21:10.674106Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_engine():\n",
    "    engine = create_engine(\n",
    "        'snowflake://{user}:{password}@{account}'.format(user=user,\n",
    "                                                         password=password,\n",
    "                                                         account=account)\n",
    "                           )\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3237ed98e55ebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T07:21:11.079936Z",
     "start_time": "2023-11-11T07:21:11.072152Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_table_name(table):\n",
    "    return f'{database}.{schema}.{table}'\n",
    "    \n",
    "def insert_data_frame_using_insert_statement(df, table):\n",
    "    print(f'dataframe length = {df.index.size}')\n",
    "    db = None\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        db = engine.connect()\n",
    "        tableName = get_table_name(table)\n",
    "        columnNames = list(df.columns.values)\n",
    "        columns = ','.join(columnNames)\n",
    "        valuePlaceHolder = ', '.join([f':{column}' for column in columnNames])\n",
    "        inserted = 0\n",
    "\n",
    "        with tqdm(total=len(df.index)) as pbar:\n",
    "            batch, tempPlaceHolder, tempValues = 0, [], {}\n",
    "            for i, row in enumerate(df.values):\n",
    "                tempPlaceHolder.append(\n",
    "                    \"(\" + ', '.join([f':{column}_{batch}' for column in columnNames]) + \")\")\n",
    "                for i, column in enumerate(columnNames):\n",
    "                    tempValues[f'{column}_{batch}'] = row[i]\n",
    "\n",
    "                batch += 1\n",
    "                if batch == 16384:\n",
    "                    valuePlaceHolder = ','.join(tempPlaceHolder)\n",
    "                    sql = text(\n",
    "                        f'insert into {tableName}({columns}) values {valuePlaceHolder}')\n",
    "                    insert = db.execute(sql, tempValues)\n",
    "                    tempValues = {}\n",
    "                    tempPlaceHolder = []\n",
    "                    inserted += batch\n",
    "                    batch = 0\n",
    "\n",
    "                pbar.update(1)\n",
    "            if batch > 0:\n",
    "                valuePlaceHolder = ','.join(tempPlaceHolder)\n",
    "                sql = text(f'insert into  {tableName}({columns}) values {valuePlaceHolder}')\n",
    "                db.execute(sql, tempValues)\n",
    "                inserted += batch\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"there is some error\")\n",
    "        raise e\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "    print(f'{inserted} - values has been inserted in the table = {table}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305014107a3e15b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T07:21:11.555185Z",
     "start_time": "2023-11-11T07:21:11.549312Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_from_db(query):\n",
    "    query_engine = get_engine()\n",
    "    df = pd.read_sql_query(query, query_engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d203a300aa67252d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T07:22:24.198053Z",
     "start_time": "2023-11-11T07:22:14.761511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|USER_ID|SENTIMENT|\n",
      "+-------+---------+\n",
      "|user1  |positive |\n",
      "|user2  |negative |\n",
      "+-------+---------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os \n",
    "\n",
    "import findspark\n",
    "findspark.init() \n",
    "\n",
    "# Create a Spark session\n",
    "# Specify the paths to the Snowflake connector JARs\n",
    "snowflake_jdbc_jar = \"/Users/hims/Downloads/snowflake-jdbc-3.14.0.jar\"\n",
    "spark_snowflake_jar = \"/Users/hims/Downloads/spark-snowflake_2.12-2.12.0-spark_3.4.jar\"\n",
    "\n",
    "# Create a Spark session with the Snowflake connector JARs\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \",\".join([\n",
    "    '--packages net.snowflake:spark-snowflake_2.12:2.12.0-spark_3.4',\n",
    "    'net.snowflake:snowflake-jdbc:3.14.0 pyspark-shell'])\n",
    "\n",
    "if \"spark\" in locals():\n",
    "    spark.stop()\n",
    "    \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .config(\"spark.jars.packages\", \"net.snowflake:spark-snowflake_2.12:2.12.0-spark_3.4,net.snowflake:snowflake-jdbc:3.14.0 pyspark-shell\") \\\n",
    "    .getOrCreate()\n",
    "#     .config(\"spark.jars\", f\"{snowflake_jdbc_jar},{spark_snowflake_jar}\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(\"user1\", \"positive\"),\n",
    "        (\"user2\", \"negative\")]\n",
    "\n",
    "columns = [\"user_id\", \"sentiment\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "# Snowflake connection options\n",
    "snowflake_options = {\n",
    "    \"sfURL\": account_url,\n",
    "    \"sfDatabase\": \"test\",\n",
    "    \"sfWarehouse\": \"COMPUTE_WH\",\n",
    "    \"sfSchema\": \"test\",\n",
    "    \"sfUser\": user,\n",
    "    \"sfPassword\": password,\n",
    "    \"sfTable\": \"test\",\n",
    "    \"dbtable\" : \"test\"\n",
    "}\n",
    "    \n",
    "# Write DataFrame to Snowflake\n",
    "df.write.format(\"snowflake\") \\\n",
    "    .options(**snowflake_options) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"test\")\n",
    "# \n",
    "# # Read data back from Snowflake for verification\n",
    "read_df = spark.read.format(\"snowflake\").options(**snowflake_options).load()\n",
    "\n",
    "# Show the result DataFrame\n",
    "read_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc963b5dbd213e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
