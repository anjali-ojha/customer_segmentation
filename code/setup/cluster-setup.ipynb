{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! ssh -i ~/Downloads/practive.pem ubuntu@ec2-54-67-13-242.us-west-1.compute.amazonaws.com\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5aa95d6fbfe2981"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Spark Setup ######################\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de2360b0555f40b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! sudo apt install openjdk-11-jre-headless\n",
    "! export JAVA_HOME=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "! sudo apt-get update\n",
    "! sudo apt-get upgrade\n",
    "! sudo apt install python3-pip\n",
    "! pip install pyspark\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d811332b694df895"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spark Verification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89a3631ff13bc740"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python3\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.functions import collect_list\n",
    "from pyspark.sql.functions import explode, create_map\n",
    "from pyspark.sql.functions import size\n",
    "from pyspark.sql.types import IntegerType, MapType\n",
    "from pyspark.sql.types import StringType\n",
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \",\".join([\n",
    "    '--packages net.snowflake:spark-snowflake_2.12:2.12.0-spark_3.4',\n",
    "    'net.snowflake:snowflake-jdbc:3.14.0 pyspark-shell'])\n",
    "\n",
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "\n",
    "simple_data = spark.sparkContext.parallelize([[1, \"Alice\", 50]]).toDF()\n",
    "simple_data.count()\n",
    "\n",
    "@udf(StringType())\n",
    "def test_udf(s): return s + \"_test_udf\"\n",
    "\n",
    "simple_data.withColumn(\"test\", test_udf(col(\"_2\"))).show()    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5c12704f3e7d6f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kafka Setup ######################\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7a5d236c8d97ba6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! wget https://archive.apache.org/dist/kafka/3.5.0/kafka_2.12-3.5.0.tgz\n",
    "! tar -zxvf kafka_2.12-3.5.0.tgz\n",
    "! cd kafka_2.12-3.5.0\n",
    "! ./bin/zookeeper-server-start.sh config/zookeeper.properties &\n",
    "! sleep 5\n",
    "! ./bin/kafka-server-start.sh config/server.properties &\n",
    "! pip uninstall kafka-python"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7462c3e70cef9ee2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kafka Verification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dd073f81e846279"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "##### Producer ########\n",
    "from kafka import KafkaProducer\n",
    "import datetime\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
    "def publish(topic, message):\n",
    "    print(f\"{datetime.datetime.now()} publishing to {topic = }, {message = }\")\n",
    "    producer.send(topic, bytes(message, encoding='utf-8'))\n",
    "\n",
    "publish(\"test\", \"test_message1\")\n",
    "publish(\"test\", \"test_message2\")\n",
    "\n",
    "##### Consumer ########\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, DoubleType\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \",\".join([\n",
    "    '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0',\n",
    "    'org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 pyspark-shell'])\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Read Kafka\").config('spark.jars.packages', ','.join(['org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0','org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0'])).getOrCreate()\n",
    "\n",
    "df = spark.read.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"localhost:9092\").option(\"startingOffsets\", \"earliest\").option(\"subscribe\", \"test\").load().withColumn(\"value\", col(\"value\").cast(\"string\"))\n",
    "\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "902e72ba9ed1063b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Airflow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "532285a0f54c67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! sudo apt install sqlite3\n",
    "\n",
    "! sudo apt-get install libpq-dev\n",
    "\n",
    "! sudo pip install \"apache-airflow[postgres]==2.5.0\" --constraint \"https://raw.githubusercontent.com/apache/airflow/constraints-2.5.0/constraints-3.7.txt\"\n",
    "\n",
    "! airflow db init\n",
    "\n",
    "! sudo apt-get install postgresql postgresql-contrib\n",
    "\n",
    "! sudo -i -u postgres\n",
    "\n",
    "! psql\n",
    "\n",
    "! CREATE DATABASE airflow;\n",
    "! CREATE USER airflow WITH PASSWORD 'airflow';\n",
    "! GRANT ALL PRIVILEGES ON DATABASE airflow TO airflow;\n",
    "\n",
    "! exit\n",
    "\n",
    "! cd airflow\n",
    "\n",
    "! sed -i 's#sqlite:////home/ubuntu/airflow/airflow.db#postgresql+psycopg2://airflow:airflow@localhost/airflow#g' airflow.cfg\n",
    "\n",
    "! sed -i 's#SequentialExecutor#LocalExecutor#g' airflow.cfg\n",
    "\n",
    "! airflow db init\n",
    "\n",
    "! airflow users create -u airflow -f airflow -l airflow -r Admin -e airflow@gmail.com\n",
    "\n",
    "! airflow webserver &\n",
    "\n",
    "! airflow scheduler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75d6c9ef2e03ed44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
